{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "This project provides the three ways to update CPI data, such as append load, trancate and load, and incremental load.\n",
    "- \"Get the Latest Data\" enables users to get the latest CPI data by inputing any dates.\n",
    "- \"Load Data\" shows the three ways to load the data up to the date which users input.\n",
    "- \"Compare Performance\" illustrates the difference of processing speed among these three ways.\n",
    "\n",
    "These services will make users decide which way to choose for their development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "1. Import necessary libraries.\n",
    "2. Define function of loading CPI data into dataframe.\n",
    "3. Define function of getting the latest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "def load_data(url):\n",
    "    response = requests.get(url)\n",
    "    cpi_data = BytesIO(response.content)\n",
    "    df = pd.read_excel(cpi_data)\n",
    "    return df\n",
    "\n",
    "def get_latest_data(df, pull_date):\n",
    "    year, month, day = pull_date.split('-')\n",
    "    year = year[2:]\n",
    "    month = str(int(month))\n",
    "    col_name  = f'PCPI{year}M{month}'\n",
    "    df_filtered = df[['DATE', col_name]]\n",
    "    df_filtered = df_filtered.rename(columns={col_name: 'CPI'})\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Latest Data\n",
    "Write any pull date from 1998-11-01 to 2025-2-28 and run the code to see the result.\n",
    "\n",
    "This project manually vefities that the following validation works.\n",
    "- If users select the date before 1998-11-01, pull date is set to be 1998-11-01.\n",
    "- If users select the date after 2025-2-28, pull date is set to be 2025-2-28.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2024:09</td>\n",
       "      <td>314.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2024:10</td>\n",
       "      <td>315.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2024:11</td>\n",
       "      <td>316.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>2024:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>2025:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE      CPI\n",
       "932  2024:09  314.686\n",
       "933  2024:10  315.454\n",
       "934  2024:11  316.441\n",
       "935  2024:12      NaN\n",
       "936  2025:01      NaN"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "url = 'https://www.philadelphiafed.org/-/media/FRBP/Assets/Surveys-And-Data/real-time-data/data-files/xlsx/pcpiMvMd.xlsx?sc_lang=en&hash=E41A743DC6423F950B10C3DE7A4F674D'\n",
    "pull_date = '2024-12-01'\n",
    "\n",
    "pull_date = datetime.datetime.strptime(pull_date, '%Y-%m-%d').date()\n",
    "\n",
    "min_date = datetime.date(1998, 11, 1)\n",
    "max_date = datetime.date(2025, 2, 28)\n",
    "\n",
    "pull_date = min(max(pull_date, min_date), max_date)\n",
    "\n",
    "latest_data = get_latest_data(load_data(url), str(pull_date))\n",
    "latest_data.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can set a pull date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pull_date = '1998-12-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Append Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_append(pull_date, con):\n",
    "    latest_data = get_latest_data(load_data(url), pull_date)\n",
    "    latest_data = latest_data.dropna(subset=['CPI'])\n",
    "    existing_dates = con.execute('SELECT DATE FROM cpi_table').fetchdf()['DATE'].tolist()\n",
    "    latest_data = latest_data[~latest_data['DATE'].isin(existing_dates)]\n",
    "    if not latest_data.empty:\n",
    "        latest_data.to_sql('cpi_table', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\3060384955.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATE         CPI\n",
      "0  1998:11  164.300003\n",
      "1  1998:10  164.000000\n",
      "2  1998:09  163.600006\n",
      "3  1998:08  163.600006\n",
      "4  1998:07  163.300003\n"
     ]
    }
   ],
   "source": [
    "con_append = duckdb.connect('cpi_append.duckdb')\n",
    "con_append.execute('DROP TABLE IF EXISTS cpi_table')\n",
    "con_append.execute(\"\"\"\n",
    "    CREATE TABLE cpi_table (\n",
    "        DATE STRING,\n",
    "        CPI FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "update_append(user_pull_date, con_append)\n",
    "updated_records = con_append.execute('SELECT * FROM cpi_table ORDER BY DATE DESC LIMIT 5').fetchdf()\n",
    "print(updated_records)\n",
    "\n",
    "con_append.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Truncate and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_truncate(pull_date, con):\n",
    "    latest_data = get_latest_data(load_data(url), pull_date)    \n",
    "    latest_data = latest_data.dropna(subset=['CPI'])\n",
    "    con.execute('DELETE FROM cpi_table')\n",
    "    if not latest_data.empty:\n",
    "        latest_data.to_sql('cpi_table', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\311833620.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATE         CPI\n",
      "0  1998:11  164.300003\n",
      "1  1998:10  164.000000\n",
      "2  1998:09  163.600006\n",
      "3  1998:08  163.600006\n",
      "4  1998:07  163.300003\n"
     ]
    }
   ],
   "source": [
    "con_truncate = duckdb.connect('cpi_truncate.duckdb')\n",
    "con_truncate.execute('DROP TABLE IF EXISTS cpi_table')\n",
    "con_truncate.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cpi_table (\n",
    "        DATE STRING,\n",
    "        CPI FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "update_truncate(user_pull_date, con_truncate)\n",
    "updated_records = con_truncate.execute(\"SELECT * FROM cpi_table ORDER BY DATE DESC LIMIT 5\").fetchdf()\n",
    "print(updated_records)\n",
    "\n",
    "con_truncate.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Incremental Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_incremental(pull_date, con):\n",
    "    latest_data = get_latest_data(load_data(url), pull_date)\n",
    "    latest_data = latest_data.dropna(subset=['CPI'])\n",
    "    existing_data = con.execute('SELECT * FROM cpi_table').fetchdf()\n",
    "\n",
    "    if not existing_data.empty:\n",
    "        merged_data = latest_data.merge(existing_data, on='DATE', suffixes=('_new', '_old'), how='left')\n",
    "\n",
    "        updated_data = merged_data[\n",
    "            (merged_data['CPI_old'].isna()) |\n",
    "            (merged_data['CPI_new'] != merged_data['CPI_old'])\n",
    "        ][['DATE', 'CPI_new']].rename(columns={'CPI_new': 'CPI'})\n",
    "\n",
    "        if not updated_data.empty:\n",
    "            date_list = updated_data['DATE'].tolist()\n",
    "            placeholders = ', '.join(['?'] * len(date_list))\n",
    "            delete_query = f'DELETE FROM cpi_table WHERE DATE IN ({placeholders})'\n",
    "            con.execute(delete_query, date_list)\n",
    "            updated_data.to_sql('cpi_table', con, if_exists='append', index=False)\n",
    "    else:\n",
    "        latest_data.to_sql('cpi_table', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\2498723605.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATE         CPI\n",
      "0  1998:11  164.300003\n",
      "1  1998:10  164.000000\n",
      "2  1998:09  163.600006\n",
      "3  1998:08  163.600006\n",
      "4  1998:07  163.300003\n"
     ]
    }
   ],
   "source": [
    "con_incremental = duckdb.connect('cpi_incremental.duckdb')\n",
    "con_incremental.execute('DROP TABLE IF EXISTS cpi_table')\n",
    "con_incremental.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cpi_table (\n",
    "        DATE STRING,\n",
    "        CPI FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "update_incremental(user_pull_date, con_incremental)\n",
    "updated_records = con_incremental.execute(\"SELECT * FROM cpi_table ORDER BY DATE DESC LIMIT 5\").fetchdf()\n",
    "print(updated_records)\n",
    "\n",
    "con_incremental.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can set start and end date of loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2025-01-30\"\n",
    "end_date = \"2025-02-01\"\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function of measuring time of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(update_method, con):\n",
    "    start_time = time.time()\n",
    "    for pull_date in date_range:\n",
    "        update_method(pull_date.strftime('%Y-%m-%d'), con)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check the performance of Append Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\3060384955.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time of Append: 23.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\3060384955.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "con_append = duckdb.connect('cpi_append.duckdb')\n",
    "con_append.execute('DROP TABLE IF EXISTS cpi_table')\n",
    "con_append.execute(\"\"\"\n",
    "    CREATE TABLE cpi_table (\n",
    "        DATE STRING,\n",
    "        CPI FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(f'Total Execution Time of Append: {measure_time(update_append, con_append):.2f} seconds')\n",
    "\n",
    "con_append.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check the performance of Truncate and Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\311833620.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n",
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\311833620.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n",
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\311833620.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time of 'Truncate': 25.38 seconds\n"
     ]
    }
   ],
   "source": [
    "con_truncate = duckdb.connect('cpi_truncate.duckdb')\n",
    "con_truncate.execute('DROP TABLE IF EXISTS cpi_table')\n",
    "con_truncate.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cpi_table (\n",
    "        DATE STRING,\n",
    "        CPI FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Total Execution Time of 'Truncate': {measure_time(update_truncate, con_truncate):.2f} seconds\")\n",
    "\n",
    "con_truncate.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check the performance of Incremental Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\2498723605.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  latest_data.to_sql('cpi_table', con, if_exists='append', index=False)\n",
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\2498723605.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  updated_data.to_sql('cpi_table', con, if_exists='append', index=False)\n",
      "C:\\Users\\oiwah\\AppData\\Local\\Temp\\ipykernel_23928\\2498723605.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  updated_data.to_sql('cpi_table', con, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time of 'Truncate': 21.84 seconds\n"
     ]
    }
   ],
   "source": [
    "con_incremental = duckdb.connect('cpi_incremental.duckdb')\n",
    "con_incremental.execute('DROP TABLE IF EXISTS cpi_table')\n",
    "con_incremental.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cpi_table (\n",
    "        DATE STRING,\n",
    "        CPI FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Total Execution Time of 'Truncate': {measure_time(update_incremental, con_incremental):.2f} seconds\")\n",
    "\n",
    "con_truncate.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Times are different by testing. So, I will update them at last.\n",
    " \n",
    "The processing times were shortest for append load (15.6 seconds), followed by incremental load (17.85 seconds), and longest for truncate and load (22.2 seconds). In terms of speed alone, append load is the fastest since it simply adds new data, while truncate and load is the slowest as it reuploads the entire dataset each time. Incremental load falls in between, as it updates only the differences, making its processing time proportional to the amount of data uploaded.\n",
    "\n",
    "From a data quality perspective, append load risks degrading accuracy because historical data is periodically updated, leading to inconsistencies. However, replacing the entire dataset every time is unnecessary—updating only the changes is sufficient. Balancing both data quality and processing speed, the most appropriate approach for handling CPI data is incremental load, as it efficiently maintains accuracy while keeping processing time manageable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
